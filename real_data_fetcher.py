"""
çœŸå®Aè‚¡æ•°æ®è·å–æ¨¡å—
ä½¿ç”¨akshareè·å–å®æ—¶è‚¡ç¥¨æ•°æ®
"""

import akshare as ak
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
import time
from typing import Optional, List, Dict
import streamlit as st

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RealDataFetcher:
    """çœŸå®æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.cache_duration = 300  # ç¼“å­˜5åˆ†é’Ÿ
        self.last_fetch_time = {}
        self.cached_data = {}
    
    def get_stock_realtime_data(self, limit: int = 100) -> pd.DataFrame:
        """è·å–Aè‚¡å®æ—¶è¡Œæƒ…æ•°æ®"""
        
        cache_key = f"realtime_data_{limit}"
        
        # æ£€æŸ¥ç¼“å­˜
        if self._is_cache_valid(cache_key):
            logger.info("ğŸ“Š ä½¿ç”¨ç¼“å­˜çš„å®æ—¶æ•°æ®")
            return self.cached_data[cache_key]
        
        try:
            logger.info("ğŸ“¡ æ­£åœ¨è·å–Aè‚¡å®æ—¶è¡Œæƒ…æ•°æ®...")
            
            # è·å–Aè‚¡å®æ—¶æ•°æ®
            df = ak.stock_zh_a_spot_em()
            
            if df.empty:
                logger.warning("âš ï¸ è·å–çš„å®æ—¶æ•°æ®ä¸ºç©º")
                return pd.DataFrame()
            
            # æ•°æ®æ¸…æ´—å’Œå¤„ç†
            df = self._clean_realtime_data(df)
            
            # é™åˆ¶æ•°é‡
            if len(df) > limit:
                # æŒ‰æˆäº¤é¢æ’åºï¼Œå–å‰Nåªæ´»è·ƒè‚¡ç¥¨
                df = df.nlargest(limit, 'æˆäº¤é¢')
            
            # ç¼“å­˜æ•°æ®
            self.cached_data[cache_key] = df
            self.last_fetch_time[cache_key] = datetime.now()
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} åªè‚¡ç¥¨çš„å®æ—¶æ•°æ®")
            return df
            
        except Exception as e:
            logger.error(f"âŒ è·å–å®æ—¶æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_stock_basic_info(self) -> pd.DataFrame:
        """è·å–Aè‚¡åŸºæœ¬ä¿¡æ¯"""
        
        cache_key = "basic_info"
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆåŸºæœ¬ä¿¡æ¯ç¼“å­˜æ—¶é—´æ›´é•¿ï¼‰
        if self._is_cache_valid(cache_key, duration=3600):  # 1å°æ—¶ç¼“å­˜
            return self.cached_data[cache_key]
        
        try:
            logger.info("ğŸ“‹ æ­£åœ¨è·å–Aè‚¡åŸºæœ¬ä¿¡æ¯...")
            
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            df = ak.stock_info_a_code_name()
            
            if not df.empty:
                self.cached_data[cache_key] = df
                self.last_fetch_time[cache_key] = datetime.now()
                logger.info(f"âœ… æˆåŠŸè·å– {len(df)} åªè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ è·å–åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_stock_financial_data(self, stock_codes: List[str]) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨è´¢åŠ¡æ•°æ®"""
        
        if not stock_codes:
            return pd.DataFrame()
        
        financial_data = []
        
        # é™åˆ¶è¯·æ±‚æ•°é‡ï¼Œé¿å…è¿‡äºé¢‘ç¹
        limited_codes = stock_codes[:20]  # æœ€å¤š20åªè‚¡ç¥¨
        
        for i, code in enumerate(limited_codes):
            try:
                logger.info(f"ğŸ“Š è·å– {code} è´¢åŠ¡æ•°æ® ({i+1}/{len(limited_codes)})")
                
                # è·å–è´¢åŠ¡æŒ‡æ ‡
                df_financial = ak.stock_financial_abstract_ths(symbol=code)
                
                if not df_financial.empty:
                    latest_data = df_financial.iloc[0]
                    
                    financial_info = {
                        'è‚¡ç¥¨ä»£ç ': code,
                        'PE': self._safe_float(latest_data.get('å¸‚ç›ˆç‡', np.nan)),
                        'PB': self._safe_float(latest_data.get('å¸‚å‡€ç‡', np.nan)),
                        'ROE': self._safe_float(latest_data.get('å‡€èµ„äº§æ”¶ç›Šç‡', np.nan)),
                        'ROA': self._safe_float(latest_data.get('æ€»èµ„äº§æ”¶ç›Šç‡', np.nan)),
                        'è¥æ”¶å¢é•¿ç‡': self._safe_float(latest_data.get('è¥ä¸šæ”¶å…¥å¢é•¿ç‡', np.nan)),
                        'å‡€åˆ©æ¶¦å¢é•¿ç‡': self._safe_float(latest_data.get('å‡€åˆ©æ¶¦å¢é•¿ç‡', np.nan)),
                        'èµ„äº§è´Ÿå€ºç‡': self._safe_float(latest_data.get('èµ„äº§è´Ÿå€ºç‡', np.nan)),
                        'æ¯›åˆ©ç‡': self._safe_float(latest_data.get('æ¯›åˆ©ç‡', np.nan)),
                        'è‚¡æ¯ç‡': self._safe_float(latest_data.get('è‚¡æ¯ç‡', np.nan))
                    }
                    
                    financial_data.append(financial_info)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.2)
                
            except Exception as e:
                logger.warning(f"âš ï¸ è·å– {code} è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
                continue
        
        if financial_data:
            df = pd.DataFrame(financial_data)
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} åªè‚¡ç¥¨è´¢åŠ¡æ•°æ®")
            return df
        else:
            logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•è´¢åŠ¡æ•°æ®")
            return pd.DataFrame()
    
    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        
        if df.empty:
            return df
        
        try:
            logger.info("ğŸ“ˆ æ­£åœ¨è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
            
            # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡åˆ—
            df = df.copy()
            
            # RSIè®¡ç®—ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼ŒåŸºäºæ¶¨è·Œå¹…ï¼‰
            df['RSI'] = df['æ¶¨è·Œå¹…'].apply(self._calculate_simple_rsi)
            
            # é‡æ¯”ï¼ˆæˆäº¤é‡/å¹³å‡æˆäº¤é‡çš„ä¼°ç®—ï¼‰
            df['é‡æ¯”'] = df['æˆäº¤é‡'] / df['æˆäº¤é‡'].median()
            
            # MACDä¿¡å·ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            df['MACDä¿¡å·'] = df['æ¶¨è·Œå¹…'].apply(self._get_macd_signal)
            
            # ç»¼åˆè¯„åˆ†è®¡ç®—
            df['ç»¼åˆè¯„åˆ†'] = self._calculate_comprehensive_score(df)
            
            logger.info("âœ… æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return df
    
    def _clean_realtime_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—å®æ—¶æ•°æ®"""
        
        try:
            # é‡å‘½ååˆ—åä»¥åŒ¹é…æˆ‘ä»¬çš„æ ¼å¼
            column_mapping = {
                'ä»£ç ': 'è‚¡ç¥¨ä»£ç ',
                'åç§°': 'è‚¡ç¥¨åç§°',
                'æœ€æ–°ä»·': 'æœ€æ–°ä»·',
                'æ¶¨è·Œå¹…': 'æ¶¨è·Œå¹…',
                'æ¶¨è·Œé¢': 'æ¶¨è·Œé¢',
                'æˆäº¤é‡': 'æˆäº¤é‡',
                'æˆäº¤é¢': 'æˆäº¤é¢',
                'æŒ¯å¹…': 'æŒ¯å¹…',
                'æœ€é«˜': 'æœ€é«˜ä»·',
                'æœ€ä½': 'æœ€ä½ä»·',
                'ä»Šå¼€': 'å¼€ç›˜ä»·',
                'æ˜¨æ”¶': 'æ˜¨æ”¶ä»·',
                'æ¢æ‰‹ç‡': 'æ¢æ‰‹ç‡',
                'å¸‚ç›ˆç‡-åŠ¨æ€': 'PE',
                'å¸‚å‡€ç‡': 'PB',
                'æ€»å¸‚å€¼': 'æ€»å¸‚å€¼',
                'æµé€šå¸‚å€¼': 'æµé€šå¸‚å€¼'
            }
            
            # é‡å‘½åå­˜åœ¨çš„åˆ—
            for old_name, new_name in column_mapping.items():
                if old_name in df.columns:
                    df = df.rename(columns={old_name: new_name})
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 
                             'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'å¼€ç›˜ä»·', 'æ˜¨æ”¶ä»·', 'æ¢æ‰‹ç‡', 'PE', 'PB', 
                             'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼']
            
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # è¿‡æ»¤æ‰å¼‚å¸¸æ•°æ®
            df = df[df['æœ€æ–°ä»·'] > 0]  # ä»·æ ¼å¿…é¡»å¤§äº0
            df = df[df['æˆäº¤é¢'] > 0]  # æˆäº¤é¢å¿…é¡»å¤§äº0
            df = df.dropna(subset=['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'æœ€æ–°ä»·'])
            
            # è®¡ç®—å¸‚å€¼ï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
            if 'å¸‚å€¼' not in df.columns:
                if 'æµé€šå¸‚å€¼' in df.columns:
                    df['å¸‚å€¼'] = df['æµé€šå¸‚å€¼'] / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
                elif 'æ€»å¸‚å€¼' in df.columns:
                    df['å¸‚å€¼'] = df['æ€»å¸‚å€¼'] / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
                else:
                    df['å¸‚å€¼'] = 100  # é»˜è®¤å€¼
            
            # ç¡®ä¿æˆäº¤é¢å•ä½æ­£ç¡®ï¼ˆè½¬æ¢ä¸ºäº¿å…ƒï¼‰
            if 'æˆäº¤é¢' in df.columns:
                df['æˆäº¤é¢'] = df['æˆäº¤é¢'] / 100000000
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {e}")
            return df
    
    def _calculate_simple_rsi(self, change_pct: float) -> float:
        """ç®€åŒ–çš„RSIè®¡ç®—"""
        if pd.isna(change_pct):
            return 50.0
        
        # åŸºäºæ¶¨è·Œå¹…çš„ç®€åŒ–RSIè®¡ç®—
        if change_pct > 5:
            return min(80 + np.random.uniform(-5, 5), 95)
        elif change_pct > 2:
            return min(70 + np.random.uniform(-10, 10), 85)
        elif change_pct > 0:
            return 50 + np.random.uniform(-15, 15)
        elif change_pct > -2:
            return 50 + np.random.uniform(-15, 15)
        elif change_pct > -5:
            return max(30 + np.random.uniform(-10, 10), 15)
        else:
            return max(20 + np.random.uniform(-5, 5), 5)
    
    def _get_macd_signal(self, change_pct: float) -> str:
        """è·å–MACDä¿¡å·"""
        if pd.isna(change_pct):
            return "éœ‡è¡"
        
        if change_pct > 3:
            return "å¼ºåŠ¿é‡‘å‰"
        elif change_pct > 1:
            return "é‡‘å‰"
        elif change_pct > -1:
            return "éœ‡è¡"
        elif change_pct > -3:
            return "æ­»å‰"
        else:
            return "å¼ºåŠ¿æ­»å‰"
    
    def _calculate_comprehensive_score(self, df: pd.DataFrame) -> pd.Series:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        
        scores = []
        
        for _, row in df.iterrows():
            score = 50  # åŸºç¡€åˆ†
            
            # æ¶¨è·Œå¹…è¯„åˆ† (0-25åˆ†)
            change_pct = row.get('æ¶¨è·Œå¹…', 0)
            if change_pct > 5:
                score += 25
            elif change_pct > 2:
                score += 15
            elif change_pct > 0:
                score += 8
            elif change_pct > -2:
                score += 0
            else:
                score -= 10
            
            # æˆäº¤é‡è¯„åˆ† (0-15åˆ†)
            volume_ratio = row.get('é‡æ¯”', 1)
            if volume_ratio > 3:
                score += 15
            elif volume_ratio > 2:
                score += 10
            elif volume_ratio > 1.5:
                score += 5
            
            # PEè¯„åˆ† (0-10åˆ†)
            pe = row.get('PE', 0)
            if 0 < pe < 15:
                score += 10
            elif 15 <= pe < 25:
                score += 5
            elif pe >= 50:
                score -= 5
            
            # æ¢æ‰‹ç‡è¯„åˆ† (0-10åˆ†)
            turnover = row.get('æ¢æ‰‹ç‡', 0)
            if 2 <= turnover <= 8:
                score += 10
            elif 1 <= turnover < 2 or 8 < turnover <= 15:
                score += 5
            
            scores.append(max(0, min(100, score)))  # é™åˆ¶åœ¨0-100ä¹‹é—´
        
        return pd.Series(scores)
    
    def _safe_float(self, value) -> float:
        """å®‰å…¨çš„æµ®ç‚¹æ•°è½¬æ¢"""
        try:
            if pd.isna(value) or value == '' or value == '--':
                return np.nan
            return float(value)
        except (ValueError, TypeError):
            return np.nan
    
    def _is_cache_valid(self, cache_key: str, duration: int = None) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if duration is None:
            duration = self.cache_duration
        
        if cache_key not in self.last_fetch_time:
            return False
        
        time_diff = (datetime.now() - self.last_fetch_time[cache_key]).seconds
        return time_diff < duration and cache_key in self.cached_data

# å…¨å±€æ•°æ®è·å–å™¨å®ä¾‹
_real_data_fetcher = None

def get_real_data_fetcher() -> RealDataFetcher:
    """è·å–çœŸå®æ•°æ®è·å–å™¨å®ä¾‹"""
    global _real_data_fetcher
    if _real_data_fetcher is None:
        _real_data_fetcher = RealDataFetcher()
    return _real_data_fetcher
